Generative Approach to Classification

	πi = Pr(y = i) 	[probability of class i]  Σπι = 1
	Pi(x)			[probability of x's label is i]

	Joint distribution Pr(x,y) = Pr(y)Pr(x|y) = πyPy(x)
	For new x we pick the largest label

Probability Review I
	Probability spaces
	Bayes' rule

Generative Modeling in One Dimension
	wine example
	-calculate π
	-13 features (13 dimensions) [advanced]
	-for now we pick 1 feature, create the histogram, find median and variance. Then create Gaussian N(μ,σ^2) for each label
	-use Bayes' rule two classify

Probability Review II
	Random Variables
	Median
	Variance

Probability Review III
	Independent random variables (to use for multiple features on generative modeling)
	Dependence
		P(X=A)P(Y=B)=/=P(X=A and Y=B)
		positevely correlated	E[HW]>E[H]E[W]		
	Correlation coefficient r ε [-1,1]  
	types of correlation
		positively		r>0
		negatively		r<-1	E[HW]<E[H]E[W]
		uncorrelated	r=0		E[HW]=E[H]E[W]
	Covariance
		r=cov(X,Y)= E[(X-E[X])(Y-E[Y])]
					E[XY] - E[X]E[Y]
	Correlation
		corr(X,Y) = cov(X,Y)/σ(X)σ(Y)
	If X,Y independent => cov(X,Y) = 0 

Two Dimensional Generative Modeling
	Bivariate Gaussian
			(13.7)		(0.20 0.06)
		μ = ( 3.0)  Σ = (0.06 0.12)	
	0.20: variance along the y direction
	0.12: variance along the x direction
	0.06: covariance of the 2 features (both 0.06 points are the same)

